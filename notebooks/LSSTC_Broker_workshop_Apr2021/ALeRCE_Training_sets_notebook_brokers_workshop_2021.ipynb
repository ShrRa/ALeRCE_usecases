{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ALeRCE_ML_training_sets.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZixz5jSqXVB"
      },
      "source": [
        "# ALeRCE training sets and classifiers\n",
        "\n",
        "```Authors: Rodrigo Carrasco-Davis, Ignacio Reyes. Last updated: 20210405```\n",
        "\n",
        "For more information about the ALeRCE broker, please visit http://alerce.science/, or take a look to our presentation paper: Förster et al. 2020 (https://arxiv.org/abs/2008.03311)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05F_iawUqXVN"
      },
      "source": [
        "# Requirements <a class=\"anchor\" id=\"req\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0u_g7s5qXVP"
      },
      "source": [
        "Install and import the new alerce API client (source code on https://github.com/alercebroker/alerce_client)\n",
        "\n",
        "You can use the following command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfRRAhD_qXVQ"
      },
      "source": [
        "!pip install alerce"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2fr6NRaqXVR"
      },
      "source": [
        "from IPython.display import display\n",
        "from IPython.core.display import display, HTML\n",
        "#display(HTML(\"<style>.container { width:70% !important; }</style>\"))\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "from astropy.time import Time\n",
        "import astropy.units as units\n",
        "from astropy.coordinates import SkyCoord\n",
        "import ephem\n",
        "\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "import pickle\n",
        "import psycopg2\n",
        "import json\n",
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNYTPgrNqXVU"
      },
      "source": [
        "from alerce.core import Alerce\n",
        "alerce_client = Alerce()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d_cjPpXqXVW"
      },
      "source": [
        "# Stamp classifier <a class=\"anchor\" id=\"stamp\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZqwuJIZqXVW"
      },
      "source": [
        "## Description<a class=\"anchor\" id=\"stamp-description\"></a>\n",
        "\n",
        "In this section we will explore the results of the ALeRCE Stamp Classifier, explained in **Carrasco-Davis et al 2020 (https://arxiv.org/abs/2008.03309)**, which is based on a convolutional neural network (CNN) that uses the images and metadata of the first alert only as input. The stamp classifier uses the first alert to quickly discriminate between 5 types of objects:\n",
        "* Active galactic nuclei (AGN)\n",
        "* Supernovae(SNe)\n",
        "* Variable stars (VS)\n",
        "* Asteroids\n",
        "* Bogus alerts. \n",
        "\n",
        "The predictions of the classifier are used to sort the alerts by their probability of being a supernova so an astronomer can see them in the [Supernova Hunter](https://snhunter.alerce.online/) web interface, to then report the candidates to TNS. We also have a light curve based classifier **(Sánchez-Sáez et al. 2020; https://arxiv.org/abs/2008.03311)**, which classifies objects based on their light curve. The purpose of this classifier is to provide a more refined classification starting with at least 6 detections in a given band. For more information please check the AGN, Variable S\n",
        "\n",
        "### Data\n",
        "\n",
        "We gathered 52,244 first alerts from ZTF to build our training set. The number of samples of AGN, SN, VS, asteroid, and bogus are 14,966 (29%), 1620 (3%), 14,996 (29%), 9899 (19%), and 10,763 (20%) respectively. Training set data will be released once our paper gets accepted. The images in the alert are the science, template and difference image. We noticed each of these classes can be classified fast since they present specific properties that can be found in the information of the first alert:\n",
        "\n",
        "+ AGN: Being stochastically variable objects, an alert generated by an AGN should have flux from the source in both the reference and science stamps. Considering this feature alone, it is difficul. t to discriminate AGNs from other variable sources. Nevertheless, AGNs should lie at the centers of their host galaxies, or appear as (quasi-)stellar objects, in relatively lower stellar density fields. Thus, a change in flux will appear as a variable source, which may lie at the center of a galaxy, or even when the galaxy is not visible they tend to be in lower stellar density fields. In these cases, the alert is likely to be triggered by an AGN. In addition, AGNs are commonly found outside the Galactic plane.\n",
        "    \n",
        "+ Supernovae (SNe): An alert generated by a SN should appear as a change in flux where no unresolved sources were present. These transients tend to appear near their host galaxies, and their location should be consistent with the underlying host stellar population distribution (e.g., a SN will have a higher probability of arising from a location aligned with the disk than perpendicular to it). As such, most SN detections exhibit a visible host galaxy in both the science and reference stamps, with the flux from the SN arising only in the science and difference images. SN candidates tend to appear outside the Galactic plane due to occlusion.\n",
        "    \n",
        "+ Variable Stars (VS): The flux coming from variable stars usually appears in both the reference and science stamps. With ZTF's sensitivity, variable stars can be detected within the Milky Way or the Local Group, and thus the alert will typically not be associated with a visible host galaxy in the stamp, but rather with other point-like sources. In addition, such alerts will have a higher probability of residing at lower Galactic latitudes and in crowded fields with multiple point sources within the stamps, given the high concentration of stars in the disk and bulge of our Galaxy.\n",
        "\n",
        "+ Asteroids: Alerts from moving Solar-system objects will appear only one time at a given position, and thus will show flux only in the science and difference images. Depending on their distance and speed, they may appear elongated in the direction of motion. In addition, such alerts should have a higher probability of residing near the ecliptic.\n",
        "    \n",
        "+ Bogus alerts: Camera and telescope optics effects, such as saturated pixels at the centers of bright sources, bad columns, hot pixels, astrometric misalignment in the subtraction to compute the difference image, unbaffled internal reflections, etc., can produce bogus alerts with no interesting real source. Bogus alerts are characterized by the presence of NaN pixels due to saturation, single or multiple bright pixels with little or no spatial extension (i.e., smaller than the telescope point spread function (PSF) and nightly seeing), or lines with high or low pixel values that extend over a large portion of the stamp (hot or cold columns/rows).\n",
        "\n",
        "<img src=\"https://github.com/alercebroker/usecases/raw/master/notebooks/colab/figures/ml/class_samples.png\" width=90% />\n",
        "\n",
        "Here we show examples of the five classes that are to be discriminated by using only the first detection. For each class, the triplet of images in each row are science, reference and difference images from left to right. Each row corresponds to a different candidate. The images are cropped at the center resulting in 21x21 images, and normalized. Further details about the pre-processing of the images is explained in Carrasco-Davis et al 2020.\n",
        "\n",
        "### Model architecture: <a class=\"anchor\" id=\"CNN\"></a>\n",
        "\n",
        "<img src=\"https://github.com/alercebroker/usecases/raw/master/notebooks/colab/figures/ml/cnn_architecture.png\" width=90% />\n",
        "\n",
        "The classifier is a convolutional neural network with 5 convolutional layers, 2 max-pooling layers and 4 fully-connected layers. Some particular details are the input branches, that exploit the rotational invariance of the astronomical images, and the use of metadata as a secondary input of information to help improving the classification performance.\n",
        "\n",
        "The loss function used combines the usual cross-entropy with a regularization term that increases the entropy of the prediction, avoiding overconfident decisions. By maximizing the entropy of the output probabilities, we penalize predictions with high confidence, in order to get better insight in cases where the stamps seem equally likely to belong to more than one class. The loss function $\\mathcal{L}$ per sample is as follows:\n",
        "\n",
        "$$    \\mathcal{L} = \\underbrace{-\\sum_{c=1}^{N}y_{c}\\log{(\\hat{y}_{c})}}_{\\text{cross-entropy}} + \\underbrace{\\beta \\sum_{c=1}^{N}\\hat{y}_{c}\\log{(\\hat{y}_{c})}}_{\\text{entropy regularization}},$$\n",
        "where $N$ is the number of classes, $y_{c}$ is the one-hot encoding label (a value of 1 in the corresponding index of class, and 0 for the rest)  indexed by $c$, $\\hat{y}_{c}$ is the model prediction for class $c$, and $\\beta$ controls the regularization term in the loss function.\n",
        "\n",
        "### Clasification results: <a class=\"anchor\" id=\"Results\"></a>\n",
        "\n",
        "<img src=\"https://github.com/alercebroker/usecases/raw/master/notebooks/colab/figures/ml/cm.png\" width=40%/>\n",
        "\n",
        "Our model achieves $0.95 \\pm 0.005$ of accuracy in the validation set and $0.941 \\pm 0.004$ in the test set. With our five class model, we recover $87 \\pm 1\\%$ of the SNe, with only $5 \\pm 2\\%$ of false positives. By inspecting the predictions made by our model for each SN sample in the test set, we found that the results are in agreement with our initial expectations regarding the class discrimination described in the Training Data section. It is worth highlighting that the results of our model are achieved by using **the first alert only**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqN6F98RqXVY"
      },
      "source": [
        "## Getting stamps with python client <a class=\"anchor\" id=\"stamp-retrieval\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77_N51W1qXVY"
      },
      "source": [
        "### Retrieving some objects of each class\n",
        "Here we build a function that uses the ALeRCE client to query objects according to the predictions of the stamp classifier. In order to select the classifier, we define the query in terms of the classifier name, corresponding class and their minimum probability, the classes are the following strings:\n",
        "+ \"AGN\": Active Galactic Nuclei\n",
        "+ \"SN\": Supernova\n",
        "+ \"VS\": Variable star\n",
        "+ \"Asteroid\"\n",
        "+ \"Bogus\"\n",
        "\n",
        "Using the ALeRCE client we can select the min and max number of observations per object, also sort them by firstmjd, number of observations (ndet), probability of the selected class, etc. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtstpeaTqXVZ"
      },
      "source": [
        "def get_objects_per_class(classearly=\"SN\", pclassearly=0.5, n_objects=100):\n",
        "    objects = alerce_client.query_objects(\n",
        "        classifier=\"stamp_classifier\",\n",
        "        class_name=classearly,\n",
        "        probability=pclassearly,\n",
        "        count=False,\n",
        "        page_size=n_objects, \n",
        "        format='pandas')\n",
        "    objects.set_index(\"oid\", inplace=True)\n",
        "    objects.sort_values(by=\"ndet\", inplace=True, ascending=False)\n",
        "    return objects"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1k10_HHqXVZ"
      },
      "source": [
        "The previous function returns a pandas dataframe with a list of objects by their ZTF oid as index, and relevant information in their columns as we will see next.\n",
        "Now, let's query some objects for each of the classes available from the stamp classifier. Here, we are querying a few thousands of objects from the ALeRCE database. We will also sort the classes by ascending number of observations in the cases of bogus and asteroids in order to get a clean example. AGNs, VS and SNe are sorted in descending order of number of observations to better appreciate the light curves for each of these classes.\n",
        "\n",
        "**This query will take one or two minutes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "jPrxUftaqXVa"
      },
      "source": [
        "n_objects = 2500 # Objects per class to query\n",
        "early_classes = [\"AGN\", \"SN\", \"VS\", \"asteroid\", \"bogus\"] # Class identifiers to query objects\n",
        "objects = {} # Initialize dictionary to use the results per class\n",
        "for i, cl in enumerate(early_classes):\n",
        "    objects[cl] = get_objects_per_class(classearly=cl, n_objects=n_objects)\n",
        "    if i==0:\n",
        "        print(\"Result of a query using the ALeRCE client\")\n",
        "        display(objects[cl].head())\n",
        "        print(\"Columns available\", objects[cl].columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2x24SIFqXVa"
      },
      "source": [
        "If we want to retrieve the light curve of a given object using the Python client we can use the following instruction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muXs4ErZqXVb"
      },
      "source": [
        "lulu_lightcurve = alerce_client.query_detections('ZTF20aaelulu', format='pandas')\n",
        "print(lulu_lightcurve.columns)\n",
        "print(lulu_lightcurve.shape)\n",
        "display(lulu_lightcurve.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjrTm7URqXVb"
      },
      "source": [
        "If we want a stamp from the previous lightcurve we can get it using its *candid*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzJ7JaUuqXVc"
      },
      "source": [
        "lulu_candid = lulu_lightcurve.loc[lulu_lightcurve['magpsf'].idxmin()].candid\n",
        "print('The candid is', lulu_candid)\n",
        "lulu_stamp = alerce_client.get_stamps('ZTF20aaelulu', lulu_candid)\n",
        "\n",
        "# unpack the 3 stamps\n",
        "lulu_science, lulu_template, lulu_difference = [i.data for i in lulu_stamp]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xl6RqznU9Ghh"
      },
      "source": [
        "Alerce client provides a simple way to plot stamps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZNDwk9-8SaH"
      },
      "source": [
        "display(HTML(\"<style>.container { width:130% !important; }</style>\"))\n",
        "\n",
        "alerce_client.plot_stamps('ZTF20aaelulu', lulu_candid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJK8hOpbqXVl"
      },
      "source": [
        "# Light curve classifier <a class=\"anchor\" id=\"lc\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-PpC2gDqXVl"
      },
      "source": [
        "## Description <a class=\"anchor\" id=\"lc-description\"></a>\n",
        "This section shows the light curve classifier from ALeRCE, described in detail in \"Alert Classification for the ALeRCE Broker System: The Light Curve Classifier\" by Sánchez-Sáez et. al (2020, under review)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WORT4webqXVl"
      },
      "source": [
        "The training set for the light curve classifier was built by cross matching ZTF with many astronomical catalogs with objects from known categories. The current training set of ALeRCE contains more than 1700 supernovae from many subclasses, almost 35k stochastic sources (QSO, AGN, Blazar, YSO, CV/Nova) and 87k light curves from periodic stars."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9slXFQvEqXVm"
      },
      "source": [
        "### Model description\n",
        "When a light curve has more than 5 alerts in any of its bands it's classified by our light curve classifier. The model uses Machine Learning, combining feature extraction of the light curves and a model build of 4 Random Forest classifiers. Each object is classified in 15 astrophysical categories according to the following taxonomy.\n",
        "\n",
        "<img src=\"https://github.com/alercebroker/usecases/raw/master/notebooks/colab/figures/ml/taxonomy.png\" width=70%/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHB_CQUVqXVm"
      },
      "source": [
        "Our classifier takes the light curve of an object, information about non-detections (previous ZTF observations where no alerts were generated), the metadata available from ZTF (e.g. coordinates) and cross match data from WISE if available. Using that data, more than 150 features are computed.\n",
        "\n",
        "Some of the computed features are:\n",
        "* Irregular autoregressive model from Eyheramendy et al. (2018).\n",
        "* Mexican hat power spectrum from Arévalo et al. (2012).\n",
        "* Parameters from a damped random walk model from Graham et al. (2017).\n",
        "* Structure function from Schmidt et al. (2010).\n",
        "* Multiband periodogram from Mondrik et al. (2015).\n",
        "* Supernova Parametric Model, derived from the model in Villar et al. (2019a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg4bQN_yqXVm"
      },
      "source": [
        "Once the features are computed they are classified by 4 Random Forest models, grouped in a hierarchy with two levels. The random forest on the top level classifies each object into 3 main categories: stochastic, transient and periodic sources. After that, each object is processed by 3 random forest classifiers in the bottom level, each one specialized in one category of objects.\n",
        "\n",
        "For example, the Transient Random Forest provides as output a vector with 4 probabilities, which corresponds to the probability of being a SN type Ia, SN type Ibc, SN type II or superluminous supernova.\n",
        "\n",
        "Finally, the outputs of the 4 classsifiers are combined using the total probabilities rule. That means that the probability of an object being a cepheid according to our classifier is the product of the object being a periodic star (computed by the random forest of the top level) and the probability of the object being a cepheid (computed by the periodic random forest).\n",
        "\n",
        "<img src=\"https://github.com/alercebroker/usecases/raw/master/notebooks/colab/figures/ml/hierarchical_rf.png\" width=50%/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMwe3mYgqXVm"
      },
      "source": [
        "## Results\n",
        "\n",
        "The following confusion matrix is a summary of the performance of the model over the test set. This figure shows that the classifier is able to separate among the different classes. Of course some classes are difficult to distinguish, but the mistakes are \"reasonable\" in the sense that most of them choose a similar class. For example, most misclassified supernovae type Ia are labeled as another kind of supernova.\n",
        "\n",
        "The black boxes in the figure indicate the confusion inside of one of the three main categories: transient sources, periodic stars and stochastic objects.\n",
        "\n",
        "<img src=\"https://github.com/alercebroker/usecases/raw/master/notebooks/colab/figures/ml/sanchez_paper_confusion_matrix.png\" width=60%/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cOh19nP9yU0"
      },
      "source": [
        "## Training labels for light curve classifier\n",
        "\n",
        "These are the labels used in Sánchez-Sáez 2020. All the data used on that paper can be downloaded from https://zenodo.org/record/4279623\n",
        "In this notebook we will only download the labels from a copy hosted on ALeRCE servers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRt_jj9TvIJk"
      },
      "source": [
        "!wget --content-disposition https://droppy.alerce.online/$/ivMdo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isTBg4NR710v"
      },
      "source": [
        "lc_labels = pd.read_csv('labeled_set_lc_classifier_SanchezSaez_2020.csv')\n",
        "lc_labels.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bR_BCbY8csI"
      },
      "source": [
        "labels_class_count = lc_labels.groupby('classALeRCE').count()['oid']\n",
        "labels_class_count = labels_class_count.sort_values(ascending=False)\n",
        "fig = plt.figure(figsize=(14, 8))\n",
        "fig.patch.set_facecolor('white')\n",
        "plt.bar(labels_class_count.index.values, labels_class_count.values)\n",
        "plt.gca().set_yscale('log')\n",
        "plt.title('Class frequency on labeled set')\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh4MijGc9Tou"
      },
      "source": [
        "source_count = lc_labels.groupby('source').count()['oid'].sort_values(\n",
        "    ascending=False)\n",
        "\n",
        "fig = plt.figure(figsize=(14, 8))\n",
        "fig.patch.set_facecolor('white')\n",
        "plt.bar(source_count.index.values, source_count.values)\n",
        "plt.gca().set_yscale('log')\n",
        "plt.title('Training set: distribution of source catalogs')\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJJfmkMfqXVn"
      },
      "source": [
        "## Querying the DB to retrieve predictions <a class=\"anchor\" id=\"db-query\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvJBA8RiqXVn"
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/alercebroker/usecases/master/alercereaduser_v4.json\"\n",
        "params = requests.get(url).json()['params']\n",
        "    \n",
        "conn = psycopg2.connect(\n",
        "    dbname=params['dbname'], \n",
        "    user=params['user'], \n",
        "    host=params['host'], \n",
        "    password=params['password'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-mFyHlMqXVn"
      },
      "source": [
        "Let's do a query over the *probability* table to understand its structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4avAJQxzV8g"
      },
      "source": [
        "query = \"select * from taxonomy;\"\n",
        "taxonomy = pd.read_sql_query(query, conn)\n",
        "taxonomy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5o8IxFoCqXVn"
      },
      "source": [
        "query = \"select * from probability limit 10;\"\n",
        "some_probabilities = pd.read_sql_query(query, conn)\n",
        "some_probabilities"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4IOvTNcqXVp"
      },
      "source": [
        "### Retrieving the predicted class for each object according to the light curve classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEQLHoMiqXVq"
      },
      "source": [
        "# Heavy query (~ 2 min)\n",
        "query = \"select oid, class_name, probability from probability where classifier_name = 'lc_classifier' and ranking = 1;\"\n",
        "bhrf_predictions = pd.read_sql_query(query, conn)\n",
        "bhrf_predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1msy46TqXVr"
      },
      "source": [
        "## Histogram of predicted classes <a class=\"anchor\" id=\"lc-histogram\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bni6acQOqXVr"
      },
      "source": [
        "pred_classes_count = bhrf_predictions.groupby('class_name').count()['oid']\n",
        "pred_classes_count = pred_classes_count.sort_values(ascending=False)\n",
        "fig = plt.figure(figsize=(14, 10))\n",
        "fig.patch.set_facecolor('white')\n",
        "plt.bar(pred_classes_count.index.values, pred_classes_count.values)\n",
        "plt.gca().set_yscale('log')\n",
        "plt.title('Predicted class frequency')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK3aXxXX3LjL"
      },
      "source": [
        "# Validation: Checking the quality of the predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGENvyFIqXVe"
      },
      "source": [
        "## Light curve lengths for stamp classifier predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm5LTtyoqXVf"
      },
      "source": [
        "The distribution of the number of detections per class can give us insights on how well the classifier is working. For instance, for AGNs, SNe, and VS, we expect to see more than one detection for these classes. The objects belonging to these classes and have one detection could be new objects or the ones visited only once, short transients, or errors in the classification. For asteroids and bogus class, we expect to have objects with one detection only."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L13k_5WqXVf"
      },
      "source": [
        "fig, ax = plt.subplots(2, 3, figsize=(20, 8))\n",
        "fig.set_facecolor('white')\n",
        "bins = np.arange(0, 40)\n",
        "ax = ax.flatten()\n",
        "fontsize = 16\n",
        "\n",
        "fig.suptitle('# of detections vs predicted class (stamp classifier)', fontsize=fontsize)\n",
        "\n",
        "# Concatenated dataframe with all the classes\n",
        "h, _ = np.histogram(pd.concat(list(objects.values()), axis=0).ndet, bins=bins, density=True)\n",
        "ax[0].bar(bins[:-1], h, label=\"all_data\")\n",
        "ax[0].set_title(\"all data\", fontsize=fontsize)\n",
        "ax[0].tick_params(axis='both', which='major', labelsize=fontsize)\n",
        "ax[0].set_ylim([0, 1])\n",
        "\n",
        "for i, (cl, df) in enumerate(objects.items()):\n",
        "    # Histogram per class\n",
        "    h, bins = np.histogram(df.ndet, bins=bins, density=True)\n",
        "    ax[i+1].bar(bins[:-1], h, label=cl)\n",
        "    ax[i+1].set_title(cl, fontsize=fontsize)\n",
        "    ax[i+1].tick_params(axis='both', which='major', labelsize=fontsize)\n",
        "    ax[i+1].set_ylim([0, 1])\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0rRWFRVqXVg"
      },
      "source": [
        "In our small sample we can see that most of the asteroids and bogus have only one detection, while AGNs, SNe and VS have a long tail of objects with more than one detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuB6ZRmYqXVh"
      },
      "source": [
        "## Spatial distribution of stamp classifier predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjGcs3DAqXVh"
      },
      "source": [
        "One issue when training models in astronomy is the possible biases found in the training set. One of the problems we had at the beginning was the abundance of extragalactic objects predicted near the galactic plane. As mentioned in the Introduction, SNe and AGNs are less likely to be found near the galactic plane due to occlusion. We fixed this problem by adding some features to the CNN at the fully connected layers, one of the most important are the ecliptic and galactic coordinates, so let's see how they look like per class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhzxI-RcqXVh"
      },
      "source": [
        "### Compute galactic and ecliptic coordinates\n",
        "We computed the coordinates from the meanra and mean dec using the ephem python package. Here (https://rhodesmill.org/pyephem/coordinates.html) there is a more detailed tutorial of how to use this transformation between coordinates. Now, we will take our dataframes and add ecliptic and galactic latitude and longitude as columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g9k6Q3jqXVi"
      },
      "source": [
        "def ecliptic_coordinates(df):\n",
        "    # Define the lambda function to be applied to each row of the dataframe\n",
        "    ecl = df.apply(lambda row: ephem.Ecliptic(ephem.Equatorial('%s' % (row.meanra / 15.),\n",
        "                                                               '%s' % row.meandec, epoch=ephem.J2000)), axis=1)\n",
        "    \n",
        "    # Apply the function to each row, the result is append as a new column\n",
        "    df[\"ecl_lat\"] = ecl.apply(lambda row: np.rad2deg(row.lat))\n",
        "    df[\"ecl_long\"] = ecl.apply(lambda row: np.rad2deg(row.long))\n",
        "    \n",
        "    # Return the updated dataframe\n",
        "    return df\n",
        "\n",
        "\n",
        "def galactic_coordinates(df):\n",
        "    # Define the lambda function to be applied to each row of the dataframe\n",
        "    gal = df.apply(lambda row: ephem.Galactic(ephem.Equatorial('%s' % (row.meanra / 15.),\n",
        "                                                               '%s' % row.meandec, epoch=ephem.J2000)), axis=1)\n",
        "    # Apply the function to each row, the result is append as a new column\n",
        "    df[\"gal_lat\"] = gal.apply(lambda row: np.rad2deg(row.lat))\n",
        "    df[\"gal_long\"] = gal.apply(lambda row: np.rad2deg(row.long))\n",
        "    \n",
        "    # Return the updated dataframe\n",
        "    return df\n",
        "\n",
        "# For each of our dataframe corresponding to one of the classes of the stamp classifier\n",
        "# we add the ecliptic and galactic coordinates\n",
        "for cl, df in objects.items():\n",
        "    ecl_df = ecliptic_coordinates(df)\n",
        "    gal_df = galactic_coordinates(ecl_df)\n",
        "    objects[cl] = gal_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19VvMlvJqXVi"
      },
      "source": [
        "def plot_spatial_distribution(df, ax, index=0, cmin_val=0.1, vmax_val=5, titles=\"\", fontsize=18, x_label=None, y_label=None):\n",
        "    dims = ['gal_long', 'gal_lat'] # Let's use our new column to plot the objects\n",
        "    # This is a 2D histogram of the positions of objects for each of the classes\n",
        "    _, _, _, im = ax.hist2d(df[dims].values[:, 0], df[dims].values[:, 1],\n",
        "                            (300, 300), cmap=\"viridis\", vmax=vmax_val, cmin=cmin_val)\n",
        "    ax.tick_params(axis='both', labelsize=fontsize-2)\n",
        "    ax.set_xlim([0, 360])\n",
        "    ax.set_ylim([-80, 80])\n",
        "    cbar = plt.colorbar(im,ax=ax, pad=0)\n",
        "    cbar.ax.tick_params(labelsize=fontsize-4)\n",
        "    \n",
        "    ecliptic_lat = np.zeros(500)\n",
        "    ecliptic_longi = np.linspace(0, 360, num=500)\n",
        "    # This auxiliary function computes the ecliptic plane by converting\n",
        "    # the ecliptic latitude 0 to galactic coordinates\n",
        "    # We should find many asteroids near the ecliptic\n",
        "    ecliptic = SkyCoord(ecliptic_longi, ecliptic_lat, unit='deg', frame='barycentrictrueecliptic')\n",
        "    galact_long, galact_lat = ecliptic.galactic.l.deg, ecliptic.galactic.b.deg\n",
        "    \n",
        "    ax.set_title(titles, fontsize=fontsize)\n",
        "    ax.plot(galact_long, galact_lat, \"ok\", markersize=6)\n",
        "    ax.plot(galact_long, galact_lat, \"oy\", markersize=4)\n",
        "    if not x_label is None:\n",
        "        ax.set_xlabel(x_label, fontsize=fontsize)\n",
        "    if not y_label is None:\n",
        "        ax.set_ylabel(y_label, fontsize=fontsize)\n",
        "    \n",
        "    return ax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uroweRApqXVi"
      },
      "source": [
        "fig, ax = plt.subplots(2, 3, figsize=(3*10, 2*6))\n",
        "fig.set_facecolor('white')\n",
        "plt.subplots_adjust(wspace=0.0, hspace=0.15)\n",
        "ax = ax.flatten() # A trick to iterate over the axis of a subplot array\n",
        "titles = [\"all objects\", ] + list(objects.keys())\n",
        "# This is just to control the saturation of the histograms, the larger\n",
        "# the number, the larger the amount of objects needed in the same location to increase the color scale\n",
        "max_count_per_class = dict(zip(titles, [20, 5, 5, 10, 5, 5])) \n",
        "\n",
        "for i in range(6):\n",
        "    x_label = None\n",
        "    y_label = None\n",
        "    if i == 0:\n",
        "        df = pd.concat(list(objects.values()), axis=0)\n",
        "    else:\n",
        "        df = list(objects.values())[i-1]\n",
        "    \n",
        "    if i in [0, 3]:\n",
        "        y_label = \"Galactic Latitude\"\n",
        "    if i in [3, 4, 5]:\n",
        "        x_label = \"Galactic Longitude\"\n",
        "    ax[i] = plot_spatial_distribution(df, ax[i], titles=titles[i], vmax_val=max_count_per_class[titles[i]], x_label=x_label, y_label=y_label)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyuIvDHzqXVj"
      },
      "source": [
        "Here us the spatial distribution for the unlabeled data, and distribution of predictions per class. The colorbar indicates the density of points. The ecliptic is shown with a yellow line with black edges. The distributions are shown as a 2d histogram of density of alerts. Extragalactic sources (SNe and AGNs) are found outside the Galactic plane. On the contrary, VS are concentrated in the Galactic plane. Asteroids are near the ecliptic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3qOIrIGqXVr"
      },
      "source": [
        "## Spatial distribution of the light curve classifier predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7jLYpm829YJ"
      },
      "source": [
        "### Galactic sources (LPV, CEP, YSO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFakUQBJqXVs"
      },
      "source": [
        "Taking the subset where the predicted class is a Long Period Variable, a Cepheid or a Young Stellar Object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCHE1_9-qXVs"
      },
      "source": [
        "galactic_sources = bhrf_predictions[bhrf_predictions['class_name'].isin(\n",
        "    ['LPV', 'CEP', 'YSO'])]\n",
        "galactic_sources"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7qfm66MqXVs"
      },
      "source": [
        "If we want to plot the position of each source we need its coordinates. We can find the galactic coordinates for the classified light curves in the *feature* table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeCT2T3LqXVs"
      },
      "source": [
        "# Heavy query (~ 2 min)\n",
        "query = \"select oid, name, value from feature where name = 'gal_l' or name = 'gal_b';\"\n",
        "features = pd.read_sql_query(query, conn)\n",
        "features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQzivIT2qXVt"
      },
      "source": [
        "gal_l = features[features.name == 'gal_l'].copy()\n",
        "gal_l.rename(columns={'value': 'gal_l'}, inplace=True)\n",
        "gal_l.drop(columns=['name'], inplace=True)\n",
        "gal_l.set_index('oid', inplace=True)\n",
        "\n",
        "gal_b = features[features.name == 'gal_b'].copy()\n",
        "gal_b.rename(columns={'value': 'gal_b'}, inplace=True)\n",
        "gal_b.drop(columns=['name'], inplace=True)\n",
        "gal_b.set_index('oid', inplace=True)\n",
        "\n",
        "coordinates = pd.concat([gal_l, gal_b], sort=True, axis=1)\n",
        "coordinates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8vK-InlqXVt"
      },
      "source": [
        "Sample 1000 objects per class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3_YaTwiqXVt"
      },
      "source": [
        "n_per_class = 1000        # sample size\n",
        "replace = False  # with replacement\n",
        "fn = lambda obj: obj.loc[np.random.choice(obj.index, n_per_class, replace),:]\n",
        "galactic_sources_subset = galactic_sources.groupby('class_name', as_index=False).apply(fn)\n",
        "galactic_sources_subset = galactic_sources_subset.droplevel(level=0)\n",
        "galactic_sources_subset\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A33EoFJqXVu"
      },
      "source": [
        "coordinates_subset = coordinates.loc[galactic_sources_subset.oid]\n",
        "fig = plt.figure(figsize=(14, 10))\n",
        "fig.patch.set_facecolor('white')\n",
        "plt.scatter(\n",
        "    coordinates_subset.values[:, 0],\n",
        "    coordinates_subset.values[:, 1],\n",
        "    alpha=0.2,\n",
        "    s=galactic_sources_subset.probability*100\n",
        ")\n",
        "plt.xlabel('Galactic latitude [deg]')\n",
        "plt.ylabel('Galactic longitude [deg]')\n",
        "plt.title('Spatial distribution of predictions: LPV, CEP, YSO')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhf7IovbqXVu"
      },
      "source": [
        "### Extragalactic sources (QSO, AGN, Blazar, SNe)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qg5nw7W0qXVu"
      },
      "source": [
        "extragalactic_sources = bhrf_predictions[bhrf_predictions['class_name'].isin(\n",
        "    ['QSO', 'Blazar', 'SNIa', 'SNII', 'AGN', 'SNIbc', 'SLSN'])]\n",
        "extragalactic_sources"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vh8r4jPzqXVv"
      },
      "source": [
        "n_per_class = 100        # sample size\n",
        "replace = False  # with replacement\n",
        "fn = lambda obj: obj.loc[np.random.choice(obj.index, n_per_class, replace),:]\n",
        "extragalactic_sources_subset = extragalactic_sources.groupby('class_name', as_index=False).apply(fn)\n",
        "extragalactic_sources_subset = extragalactic_sources_subset.droplevel(level=0)\n",
        "extragalactic_sources_subset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWeiMyZDqXVv"
      },
      "source": [
        "coordinates_subset = coordinates.loc[extragalactic_sources_subset.oid]\n",
        "fig = plt.figure(figsize=(14, 10))\n",
        "fig.patch.set_facecolor('white')\n",
        "plt.scatter(\n",
        "    coordinates_subset.values[:, 0],\n",
        "    coordinates_subset.values[:, 1],\n",
        "    alpha=0.4,\n",
        "    s=extragalactic_sources_subset.probability*100\n",
        ")\n",
        "plt.xlabel('Galactic latitude [deg]')\n",
        "plt.ylabel('Galactic longitude [deg]')\n",
        "plt.title('Spatial distribution of extragalactic pred. sources')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKJp5faEylzC"
      },
      "source": [
        "# Appendix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1s360t4qXVc"
      },
      "source": [
        "### Let's see some stamps "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RfUtEISqXVd"
      },
      "source": [
        "We will create a simple function that plots the light curve given an object id (oid), a dataframe with detections and a dataframe with non detections. This function will be used to plot light curves of some objects predicted by the stamp classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EkMYFFQqXVd"
      },
      "source": [
        "def plotLC(SN_det, SN_nondet=None, title='', period=None, omit_figure=False, extended=False):\n",
        "    colors = {1: '#56E03A', 2: '#D42F4B'} \n",
        "    if omit_figure:\n",
        "        fig = plt.gcf()\n",
        "        ax = plt.gca()\n",
        "    else:\n",
        "        fig, ax = plt.subplots(figsize = (14, 7))\n",
        "    fig.set_facecolor('white')\n",
        "    labels = {1: 'g', 2: 'r'}\n",
        "    markers = {1: 'o', 2: 's'}\n",
        "    sizes = {1: 30, 2: 60}\n",
        "    \n",
        "    # loop the passbands\n",
        "    for fid in [1, 2]:\n",
        "        # plot detections if available        \n",
        "        fid_df = SN_det[SN_det.fid == fid]\n",
        "        if len(fid_df) == 0:\n",
        "            continue\n",
        "        if period is not None:\n",
        "            mjd = (fid_df.mjd % period) / period\n",
        "        else:\n",
        "            mjd = fid_df.mjd\n",
        "        if (extended and fid_df.iloc[0].isdiffpos==1) or not fid_df.iloc[0].corrected:\n",
        "            mags = fid_df.magpsf\n",
        "            errors = fid_df.sigmapsf\n",
        "        else:\n",
        "            mags = fid_df.magpsf_corr\n",
        "            errors = fid_df.sigmapsf_corr_ext\n",
        "            \n",
        "        ax.errorbar(mjd, mags, \n",
        "                    yerr = errors, c=colors[fid], label=labels[fid], marker=markers[fid], ls='none')\n",
        "\n",
        "        # plot non detections if available\n",
        "        if (SN_nondet is not None) and (len(SN_nondet) != 0) and (period is not None):\n",
        "            mask = (SN_nondet.fid == fid) & (SN_nondet.diffmaglim > -900)\n",
        "            if np.sum(mask) > 0:     \n",
        "                # non detections index is mjd\n",
        "                ax.scatter(SN_nondet[mask].mjd, SN_nondet[mask].diffmaglim, c=colors[fid], alpha = 0.5,\n",
        "                    marker='v', label=\"lim.mag. %s\" % labels[fid], s=sizes[fid])\n",
        "\n",
        "    ax.set_title(title)\n",
        "    if period is not None:\n",
        "        ax.set_xlabel(f'Phase (period={period:.3f})')\n",
        "    else:\n",
        "        ax.set_xlabel('Date [mjd]')\n",
        "    ax.set_ylabel(\"Apparent magnitude [mag]\")\n",
        "    ax.legend()\n",
        "    ax.invert_yaxis()\n",
        "    \n",
        "def getObjectData(oid, doLC=False, dostamp=False, period=None, extended=False):\n",
        "    results = {\"oid\": oid}\n",
        "        \n",
        "    # query detections\n",
        "    SN_det = alerce_client.query_detections(oid, format='pandas')\n",
        "    SN_det = SN_det.sort_values(\"mjd\")\n",
        "    results[\"lc_det\"] = SN_det\n",
        "        \n",
        "    # query non detections\n",
        "    SN_nondet = alerce_client.query_non_detections(oid, format='pandas')\n",
        "    if len(SN_nondet)!=0:\n",
        "        SN_nondet = SN_nondet.sort_values(\"mjd\")\n",
        "        results[\"lc_nondet\"] = SN_nondet\n",
        "    \n",
        "    # plot the LC\n",
        "    if doLC:\n",
        "        plotLC(SN_det, SN_nondet=SN_nondet, title=oid, period=period, extended=extended)\n",
        "        \n",
        "    # show the first image stamp\n",
        "    if dostamp:\n",
        "        alerce_client.plot_stamps(oid)\n",
        "        \n",
        "    # return data\n",
        "    return results\n",
        "\n",
        "def plot_some_LC(df, n_examples=3):\n",
        "    for i in range(n_examples):\n",
        "        object_id = df.iloc[i].name\n",
        "        extended = df.iloc[i]['class'] == 'SN'\n",
        "        print(f\"https://dev.alerce.online/object/{object_id}\")\n",
        "        getObjectData(object_id, doLC=True, dostamp=True, period=None, extended=extended)\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "wtmj-X80qXVe"
      },
      "source": [
        "display(HTML(\"<style>.container { width:130% !important; }</style>\"))\n",
        "for cl, df in objects.items():\n",
        "    display(HTML(f\"<h1>{cl}</h1>\"))\n",
        "    if cl in [\"asteroid\", \"bogus\"]: # Just to have well classified samples to show\n",
        "        df.sort_values(by=\"ndet\", inplace=True)\n",
        "    else:\n",
        "        df = df[df.ndet > 20].sample(frac=1)  # shuffle answer\n",
        "    plot_some_LC(df, n_examples=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcmX1YmzqXVj"
      },
      "source": [
        "## Stamp classifier probabilities per class as a function of the position\n",
        "\n",
        "Even though most of the objects per class lie in a reasonable position according to their nature, there are some errors or contamination between classes. It is interesting to see how certain is the stamp classifier for each class depending on their position, so let’s plot the probability of each object belonging to each class in the same galactic coordinates projection. We only have to modify our previous “plot_spatial_distribution” function to make a scatter plot instead of the 2d histogram. We will fill each scatter dot with a colormap and size that reflects their probability."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6peYgBVqXVk"
      },
      "source": [
        "def plot_spatial_probabilities(df, ax, index=0, cmin_val=0.1, vmax_val=5, titles=\"\", fontsize=18, x_label=None, y_label=None):\n",
        "    # We sort the rows of the dataframe first in order to reduces biases when \"painting\" the plot with the scatter\n",
        "    df = df.sample(frac=1) \n",
        "    dims = ['gal_long', 'gal_lat'] # Let's use our new column to plot the objects\n",
        "    # We will use the normalized probabilities (between 0 and 1) to scale the size of each dot according \n",
        "    # the their probability of belonging to the respective class\n",
        "    normalized_probabilities_per_class = df[\"probability\"].values - np.amin(df[\"probability\"].values)\n",
        "    normalized_probabilities_per_class = normalized_probabilities_per_class/np.amax(normalized_probabilities_per_class)\n",
        "    # Variable size dots for the scatter plot\n",
        "    variable_sizes = 10 + normalized_probabilities_per_class*100\n",
        "    color_map = plt.cm.get_cmap('viridis')\n",
        "    im = ax.scatter(df[dims].values[:, 0], df[dims].values[:, 1], c=df[\"probability\"].values, cmap=color_map,\n",
        "                   s=variable_sizes, alpha=0.7)\n",
        "    ax.tick_params(axis='both', labelsize=fontsize-2)\n",
        "    ax.set_xlim([0, 360])\n",
        "    ax.set_ylim([-80, 80])\n",
        "    cbar = plt.colorbar(im,ax=ax, pad=0)\n",
        "    cbar.ax.tick_params(labelsize=fontsize-4)\n",
        "    \n",
        "    ecliptic_lat = np.linspace(0, 0, num=500)\n",
        "    ecliptic_longi = np.linspace(0, 360, num=500)\n",
        "    # This auxiliary function computes the ecliptic plane by converting\n",
        "    # the ecliptic latitude 0 to galactic coordinates\n",
        "    ecliptic = SkyCoord(ecliptic_longi, ecliptic_lat, unit='deg', frame='barycentrictrueecliptic')\n",
        "    galact_long, galact_lat = ecliptic.galactic.l.deg, ecliptic.galactic.b.deg\n",
        "    \n",
        "    ax.set_title(titles, fontsize=fontsize)\n",
        "    ax.plot(galact_long, galact_lat, \"ok\", markersize=6)\n",
        "    ax.plot(galact_long, galact_lat, \"oy\", markersize=4)\n",
        "    \n",
        "    if not x_label is None:\n",
        "        ax.set_xlabel(x_label, fontsize=fontsize)\n",
        "    if not y_label is None:\n",
        "        ax.set_ylabel(y_label, fontsize=fontsize)\n",
        "    \n",
        "    return ax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IpIcB2oqXVk"
      },
      "source": [
        "fig, ax = plt.subplots(2, 3, figsize=(3*10, 2*6))\n",
        "fig.set_facecolor('white')\n",
        "plt.subplots_adjust(wspace=0.0, hspace=0.15)\n",
        "ax = ax.flatten() # A trick to iterate over the axis of a subplot array\n",
        "titles = [\"all objects\", ] + list(objects.keys())\n",
        "\n",
        "for i in range(6):\n",
        "    x_label = None\n",
        "    y_label = None\n",
        "    if i == 0:\n",
        "        df = pd.concat(list(objects.values()), axis=0)\n",
        "    else:\n",
        "        df = list(objects.values())[i-1]\n",
        "    \n",
        "    if i in [0, 3]:\n",
        "        y_label = \"Galactic Latitude\"\n",
        "    if i in [3, 4, 5]:\n",
        "        x_label = \"Galactic Longitude\"\n",
        "    \n",
        "    ax[i] = plot_spatial_probabilities(df, ax[i], titles=titles[i], vmax_val=max_count_per_class[titles[i]], x_label=x_label, y_label=y_label)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t8eoqi3qXVk"
      },
      "source": [
        "For the SN class, the stamp classifier seems to be more confident about the prediction further from the ecliptic, there is a large blob of green-yellow dots at around (40, 120), while darker blobs near the ecliptic, meaning less confidence in the prediction. We can also see a greener blob near the center of the galaxy in the case of variable stars. In addition, it is also important to know the relative confidence between classes, some classes are harder to classify than others as you can see in the “all objects” scatter. Now, we will plot the distribution of probabilities per class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILTqBliSCQoi"
      },
      "source": [
        "## Supernova Hunter and astronomers feedback\n",
        "\n",
        "Every day, a group of ALeRCE astronomers inspect the predictions made by the stamp classifier using the Supenova Hunter (https://snhunter.alerce.online/) and report SN candidates to the Transient Name Server. The most interesting objects are followed up with other telescopes.\n",
        "\n",
        "As the astronomers check dozens of objects each day, they also identify stamps that are clearly misclassified by our model. To take advantage of that effort, a button was added to the SN Hunter webpage that allow us to easily keep track in a database of the bogus sources that were misclassified.\n",
        "\n",
        "<img src=\"https://github.com/alercebroker/usecases/raw/master/notebooks/colab/figures/ml/sn_hunter.png\" width=90% />\n",
        "\n",
        "This has proven very useful, because it is easy to get new non-bogus sources from crossmatch with catalogs, but bogus objects have to be tagged by ourselves. One potential pitfall of identifying bogus objects this way is that we are prone to find bogus objects that look like SN, not covering all the possible types of bogus alerts. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6Fx50O2qXVp"
      },
      "source": [
        "## Retrieving light curve features from ALeRCE database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ijKj7YsVqXVp"
      },
      "source": [
        "query = \"select name, value from feature where oid = 'ZTF20aaelulu';\"\n",
        "features = pd.read_sql_query(query, conn)\n",
        "features.iloc[:30]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rR1M2dYWqXVw"
      },
      "source": [
        "## Visualizing a sample of light curves from each predicted class <a class=\"anchor\" id=\"lc-visualization\"></a>\n",
        "We will take one object per class and show its light curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jHFxY5kqXVw"
      },
      "source": [
        "n_per_class = 1        # sample size\n",
        "minimum_probability = 0.35\n",
        "replace = False  # with replacement\n",
        "fn = lambda obj: obj.loc[np.random.choice(obj.index, n_per_class, replace),:]\n",
        "filtered_bhrf_predictions = bhrf_predictions[bhrf_predictions.probability >= minimum_probability]\n",
        "sample_per_class = filtered_bhrf_predictions.groupby('class_name', as_index=False).apply(fn)\n",
        "sample_per_class = sample_per_class.droplevel(level=0)\n",
        "sample_per_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "LoLUg7v6qXVw"
      },
      "source": [
        "fig = plt.figure(figsize=(14, 25))\n",
        "fig.patch.set_facecolor('white')\n",
        "for index in range(len(sample_per_class)):\n",
        "    astro_class = sample_per_class['class_name'].values[index]\n",
        "    oid = sample_per_class['oid'].values[index]\n",
        "    light_curve = alerce_client.query_detections(oid, format='pandas')\n",
        "    plt.subplot(8, 2, index+1)\n",
        "    period = None\n",
        "    if astro_class in ['CEP', 'E', 'DSCT', 'LPV', 'Periodic-Other', 'RRL']:\n",
        "        query = f\"select oid, name, value from feature where name = 'Multiband_period' and oid = '{oid}';\"\n",
        "        period_df = pd.read_sql_query(query, conn)\n",
        "        if len(period_df) > 0:\n",
        "            period = float(period_df.value.values[0])\n",
        "    extended = astro_class in ['SNIa', 'SNIbc', 'SNII', 'SLSN']\n",
        "    plotLC(light_curve, SN_nondet=None, title=f'{astro_class} candidate {oid}', period=period, omit_figure=True, extended=extended)\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__o_mE2broRb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}